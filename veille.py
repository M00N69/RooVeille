import streamlit as st
import feedparser
import requests
from datetime import datetime, timedelta
import os
from groq import Groq
import pandas as pd
from io import BytesIO
import concurrent.futures
from typing import List, Dict, Tuple
import time
import re
from html import unescape

# --- Configuration ---
PRODUCT_TYPES = ["Produits laitiers", "Viande", "Produits frais", "Produits de boulangerie", "Boissons", "Aliments transform√©s", "Autre"]
RISK_TYPES = ["Microbiologique", "Chimique", "Physique", "Allerg√®ne", "Fraude", "Autre"]
MARKETS = ["UE", "US", "Canada", "Royaume-Uni", "France", "International", "Autre"]

# Flux RSS optimis√©s avec gestion sp√©ciale pour Health BE
FRENCH_EU_RSS_FEEDS = {
    "EFSA": "https://www.efsa.europa.eu/en/all/rss",
    "EU Food Safety": "https://food.ec.europa.eu/node/2/rss_en",
    "ANSES": "https://www.anses.fr/fr/flux-actualites.rss",
    "Health BE": "https://www.health.belgium.be/fr/rss/news.xml",
}

FOOD_SAFETY_KEYWORDS = [
    "rappel", "contamination", "allerg√®ne", "pathog√®ne", "hygi√®ne", "r√©glementation",
    "norme", "conformit√©", "audit", "inspection", "danger", "√©valuation des risques",
    "maladie d'origine alimentaire", "tra√ßabilit√©", "HACCP", "GFSI", "pesticide", "additif",
    "emballage", "√©tiquetage", "microbiologie", "toxicologie", "nouvel aliment", "fraude alimentaire"
]

# Configuration de pertinence
PERTINENCE_LEVELS = {
    "Tr√®s pertinent": {"score": 3, "color": "üü¢", "min_threshold": 80},
    "Mod√©r√©ment pertinent": {"score": 2, "color": "üü°", "min_threshold": 60},
    "Peu pertinent": {"score": 1, "color": "üü†", "min_threshold": 40},
    "Non pertinent": {"score": 0, "color": "üî¥", "min_threshold": 0}
}

# --- Classes et fonctions optimis√©es ---

def clean_html_content(html_content: str, preserve_basic_formatting: bool = True) -> str:
    """Nettoie le contenu HTML pour l'affichage et l'analyse."""
    if not html_content:
        return ""
    
    # Decode HTML entities
    cleaned = unescape(html_content)
    
    if preserve_basic_formatting:
        # Remplace les balises de paragraphe par des retours √† la ligne
        cleaned = re.sub(r'</?p[^>]*>', '\n', cleaned)
        cleaned = re.sub(r'<br[^>]*/?>', '\n', cleaned)
        # Garde les listes avec des tirets
        cleaned = re.sub(r'<li[^>]*>', '- ', cleaned)
        cleaned = re.sub(r'</li>', '\n', cleaned)
        # Supprime toutes les autres balises HTML
        cleaned = re.sub(r'<[^>]+>', '', cleaned)
    else:
        # Supprime toutes les balises HTML
        cleaned = re.sub(r'<[^>]+>', '', cleaned)
    
    # Nettoie les espaces multiples et retours √† la ligne
    cleaned = re.sub(r'\n\s*\n', '\n\n', cleaned)  # Double retours √† la ligne max
    cleaned = re.sub(r'[ \t]+', ' ', cleaned)  # Espaces multiples
    cleaned = cleaned.strip()
    
    return cleaned

def extract_content_from_entry(entry) -> str:
    """Extrait le meilleur contenu disponible d'une entr√©e RSS."""
    content = ""
    
    # 1. Priorit√© : content:encoded (plus d√©taill√©)
    if hasattr(entry, 'content') and entry.content:
        try:
            content = entry.content[0].value
        except (IndexError, AttributeError):
            pass
    
    # 2. Fallback : summary/description
    if not content and hasattr(entry, 'summary'):
        content = entry.summary
    
    # 3. Fallback final : title
    if not content:
        content = entry.title
    
    return content

class ArticleEvaluator:
    GROQ_MODEL = "llama3-8b-8192"
    MAX_TOKENS_TRANSLATE = 500
    MAX_TOKENS_EVALUATE = 600  # Augment√© pour permettre une √©valuation plus d√©taill√©e

    def __init__(self, groq_api_key: str):
        self.client = Groq(api_key=groq_api_key) if groq_api_key else None
    
    def translate_to_french(self, text: str, content_type: str = "texte") -> Tuple[str, bool]:
        """
        Traduit un texte en fran√ßais en utilisant Groq.
        Retourne un tuple: (texte_resultat, bool_tentative_traduction)
        bool_tentative_traduction est True si une requ√™te API a √©t√© faite, False sinon.
        """
        translation_attempted = False
        if not self.client or not text or len(text.strip()) < 3:
            return text, translation_attempted
        
        # D√©tection plus robuste de l'anglais
        english_words = ['the', 'and', 'of', 'in', 'to', 'for', 'with', 'on', 'at', 'by', 'from', 'as', 'is', 'are', 'was', 'were', 'been', 'have', 'has', 'had', 'will', 'would', 'could', 'should', 'may', 'might', 'can', 'must']
        text_lower = text.lower()
        
        # Compte les mots anglais
        word_count = len(text.split())
        english_count = sum(1 for word in english_words if f' {word} ' in f' {text_lower} ' or text_lower.startswith(f'{word} ') or text_lower.endswith(f' {word}'))
        
        # Si moins de 20% de mots anglais d√©tect√©s, probablement d√©j√† en fran√ßais
        if word_count > 0 and (english_count / word_count) < 0.2:
            return text, translation_attempted # Pas de tentative de traduction
        
        translation_attempted = True # Marquer comme tentative si on passe l'heuristique
        try:
            prompt = f"""
            Traduisez ce {content_type} scientifique en fran√ßais professionnel.
            Gardez tous les termes techniques, noms d'esp√®ces, codes de r√©f√©rence, et acronymes en version originale.
            
            IMPORTANT : R√©pondez UNIQUEMENT avec la traduction fran√ßaise, rien d'autre.
            
            Texte √† traduire :
            {text}
            """
            
            response = self.client.chat.completions.create(
                messages=[{"role": "user", "content": prompt}],
                model=self.GROQ_MODEL,
                temperature=0.0,  # Plus d√©terministe
                max_tokens=self.MAX_TOKENS_TRANSLATE,
            )
            
            translated = response.choices[0].message.content.strip()
            
            # V√©rifie que la traduction n'est pas vide et diff√©rente de l'original
            if translated and len(translated) > 10 and translated != text:
                return translated, translation_attempted
            else:
                # La traduction a √©chou√© ou n'est pas satisfaisante
                return text, translation_attempted
            
        except Exception as e:
            st.warning(f"Erreur de traduction pour {content_type}: {e}. Veuillez v√©rifier votre cl√© API Groq et votre connexion r√©seau.")
            return text, translation_attempted # Retourne l'original mais signale la tentative
        
    def evaluate_pertinence(self, article_title: str, article_summary: str, user_context: str) -> Tuple[str, str, int]:
        """√âvalue la pertinence avec des crit√®res TR√àS STRICTS sur la correspondance avec les types de produits."""
        if not self.client:
            return "Non pertinent", "Cl√© API manquante", 0

        prompt = f"""
        Vous √™tes un expert en s√©curit√© alimentaire europ√©enne. Vous devez √©valuer la pertinence de cet article pour un consultant/auditeur avec un profil TR√àS SP√âCIFIQUE.

        PROFIL UTILISATEUR D√âTAILL√â:
        {user_context}

        ARTICLE √Ä √âVALUER:
        Titre: {article_title}
        R√©sum√©: {article_summary}

        ‚ö†Ô∏è R√àGLES D'√âVALUATION ULTRA-STRICTES ‚ö†Ô∏è

        üî¥ EXCLUSIONS AUTOMATIQUES (Score 0-20):
        - Alimentation animale / feed (sauf si profil inclut explicitement l'alimentation animale)
        - Cosm√©tiques, m√©dicaments, dispositifs m√©dicaux
        - Agriculture g√©n√©rale sans lien avec transformation alimentaire
        - Recherche fondamentale sans application pratique imm√©diate
        - G√©ographies non mentionn√©es dans le profil (ex: Asie si profil UE uniquement)
        - Types de produits NON list√©s dans le profil (ex: seafood si profil uniquement viande)
        - Articles g√©n√©riques sur "food" sans sp√©cification de produit

        üü† PERTINENCE FAIBLE (Score 21-45):
        - R√©glementation g√©n√©rale UE sans impact sp√©cifique sur les produits du profil
        - Mentions tangentielles des types de produits sans focus principal
        - Contexte industrie alimentaire large mais pas les produits sp√©cifiques
        - Nouvelles m√©thodologies analytiques g√©n√©rales

        üü° PERTINENCE MOD√âR√âE (Score 46-70):
        - R√©glementation applicable aux produits du profil mais impact indirect
        - Types de risques mentionn√©s dans le profil mais sur d'autres produits
        - √âvolutions g√©n√©rales des march√©s sp√©cifi√©s
        - √âtudes sur des dangers pertinents mais produits diff√©rents

        üü¢ TR√àS PERTINENT (Score 71-100):
        - CORRESPONDANCE EXACTE : Type de produit + Type de risque + March√© du profil
        - Nouvelles r√©glementations DIRECTEMENT applicables aux produits du profil
        - Rappels/alertes sur les types de produits sp√©cifiques du profil
        - Nouveaux dangers sur les produits et march√©s du profil
        - Nouvelles m√©thodes d'analyse pour les produits du profil

        EXEMPLES CONCRETS DE SCORING:
        
        Si profil = "Produits laitiers, Microbiologique, UE":
        - Article sur Listeria dans fromages UE ‚Üí Score 90-95 (PARFAIT)
        - Article sur STEC dans lait cru France ‚Üí Score 85-90 (EXCELLENT)
        - Article sur pesticides dans l√©gumes UE ‚Üí Score 15-25 (MAUVAIS: type produit)
        - Article sur Salmonella dans produits laitiers US ‚Üí Score 35-45 (MOYEN: mauvais march√©)
        - Article r√©glementation g√©n√©rale UE ‚Üí Score 40-50 (FAIBLE: trop g√©n√©ral)
        - Article sur feed contamination ‚Üí Score 0-10 (EXCLUSION)

        Si profil = "Viande, Chimique, France":
        - Article sur r√©sidus antibiotiques viande France ‚Üí Score 90-100 (PARFAIT)
        - Article sur allerg√®nes produits laitiers France ‚Üí Score 20-30 (MAUVAIS: produit + risque)
        - Article sur hormones viande UE ‚Üí Score 65-75 (BON: produit/risque, g√©o proche)
        - Article sur Campylobacter volaille France ‚Üí Score 45-55 (MOYEN: bon produit/g√©o, mauvais risque)

        Si profil = "Autre" (tous produits):
        - Soyez moins strict sur les types de produits mais maintenez les autres crit√®res

        ATTENTION MAXIMALE:
        ‚ùå Soyez IMPITOYABLE sur la correspondance exacte avec les types de produits
        ‚ùå Un article sur "l√©gumes" n'est PAS pertinent pour un profil "produits laitiers"
        ‚ùå Un article "alimentation animale" n'est PAS pertinent pour "produits pour humains"
        ‚ùå Un article "cosm√©tiques" n'est JAMAIS pertinent pour food safety
        ‚ùå G√©ographie : USA/Canada uniquement pertinents si mentionn√©s dans profil
        ‚ùå Articles g√©n√©riques sur "s√©curit√© alimentaire" sans sp√©cification = score faible

        PROCESSUS D'√âVALUATION OBLIGATOIRE:
        1. Identifiez le type de produit principal de l'article
        2. V√©rifiez s'il correspond EXACTEMENT √† un type du profil
        3. Identifiez le type de risque de l'article
        4. V√©rifiez la g√©ographie/march√©
        5. Si une des correspondances majeures √©choue ‚Üí Score maximum 45
        6. Soyez particuli√®rement strict si le profil ne contient PAS "Autre"

        R√©pondez EXACTEMENT dans ce format:
        Pertinence: [Tr√®s pertinent/Mod√©r√©ment pertinent/Peu pertinent/Non pertinent]
        Score: [nombre entre 0 et 100]
        R√©sum√©: [En 2-3 phrases, expliquez la correspondance EXACTE ou les √©l√©ments qui ne correspondent PAS au profil. Mentionnez explicitement les types de produits, risques et march√©s.]
        """
        
        try:
            response = self.client.chat.completions.create(
                messages=[{"role": "user", "content": prompt}],
                model=self.GROQ_MODEL,
                temperature=0.0,  # Plus d√©terministe pour l'√©valuation
                max_tokens=self.MAX_TOKENS_EVALUATE,
            )
            
            content = response.choices[0].message.content
            return self._parse_evaluation(content)
            
        except Exception as e:
            st.error(f"Erreur API Groq: {e}. Veuillez v√©rifier votre cl√© API Groq et votre connexion r√©seau.")
            return "Non pertinent", "Erreur d'√©valuation", 0
    
    def _parse_evaluation(self, response: str) -> Tuple[str, str, int]:
        """Parse la r√©ponse de l'API pour extraire pertinence, score et r√©sum√©."""
        # Valeurs par d√©faut s√©curis√©es
        pertinence_level = "Non pertinent"
        summary = "Impossible d'√©valuer"
        score = 0
        
        if not response:
            return pertinence_level, summary, score
        
        try:
            lines = response.split('\n')
            for line in lines:
                line_stripped = line.strip() # For whitespace
                if line_stripped.lower().startswith("pertinence:"):
                    level_text = line_stripped[len("Pertinence:"):].strip()
                    # Validation des niveaux accept√©s
                    valid_levels = ["Tr√®s pertinent", "Mod√©r√©ment pertinent", "Peu pertinent", "Non pertinent"]
                    if level_text in valid_levels: # Preserves original casing if valid
                        pertinence_level = level_text
                    # Handle cases where LLM might output "Pertinence: Tr√®s Pertinent" (title case)
                    # by checking title case version if direct match fails.
                    elif level_text.title() in valid_levels:
                         pertinence_level = level_text.title()

                elif line_stripped.lower().startswith("score:"):
                    score_text = line_stripped[len("Score:"):].strip()
                    try:
                        # Extraction du nombre m√™me s'il y a du texte autour
                        score_match = re.search(r'\d+', score_text)
                        if score_match:
                            score = int(score_match.group())
                            score = max(0, min(100, score))  # Clamp entre 0 et 100
                    except (ValueError, AttributeError):
                        score = 0 # Default if parsing fails
                elif line_stripped.lower().startswith("r√©sum√©:"): # French 'R√©sum√©'
                    summary_text = line_stripped[len("R√©sum√©:"):].strip()
                    if summary_text: # Ensure not empty
                        summary = summary_text[:400]  # Limite la taille augment√©e
        
        except Exception as e:
            st.warning(f"Erreur lors du parsing de l'√©valuation : {e}")
        
        return pertinence_level, summary, score

def apply_additional_filtering(evaluated_articles: List[Dict], user_context: str) -> List[Dict]:
    """
    Applique un filtrage suppl√©mentaire bas√© sur des mots-cl√©s pour s'assurer 
    que les articles correspondent vraiment aux types de produits du profil.
    """
    
    # Extraction des types de produits du contexte utilisateur
    context_lower = user_context.lower()
    
    # D√©finition des mots-cl√©s par type de produit (fran√ßais et anglais)
    product_keywords = {
        "produits laitiers": [
            "lait", "fromage", "yaourt", "yogourt", "beurre", "cr√®me", "lactose", "lactos√©rum", "whey", "cas√©ine",
            "dairy", "cheese", "milk", "yogurt", "yoghurt", "butter", "cream", "lactose", "casein"
        ],
        "viande": [
            "viande", "porc", "b≈ìuf", "boeuf", "volaille", "poulet", "porc", "agneau", "veau", "jambon", "saucisse",
            "meat", "beef", "pork", "chicken", "poultry", "lamb", "veal", "ham", "sausage", "bacon"
        ],
        "produits frais": [
            "l√©gumes", "fruits", "salade", "√©pinards", "tomates", "pommes", "bananes", "fraises", "herbes",
            "fresh", "vegetable", "fruit", "produce", "frais", "salad", "spinach", "tomato", "apple", "banana", "strawberry"
        ],
        "produits de boulangerie": [
            "pain", "boulangerie", "p√¢tisserie", "bl√©", "farine", "gluten", "c√©r√©ales", "biscuit", "g√¢teau",
            "bakery", "bread", "wheat", "flour", "gluten", "cereal", "cookie", "cake", "pastry"
        ],
        "boissons": [
            "boisson", "jus", "eau", "soda", "th√©", "caf√©", "vin", "bi√®re", "alcool",
            "beverage", "drink", "juice", "water", "soft drink", "tea", "coffee", "wine", "beer", "alcohol"
        ],
        "aliments transform√©s": [
            "transform√©", "pr√©par√©", "conserve", "surgel√©", "plat pr√©par√©", "sauce", "condiment",
            "processed", "prepared", "manufactured", "canned", "frozen", "ready meal", "sauce", "condiment"
        ],
        "autre": []  # Le type "autre" accepte tout
    }
    
    # Mots-cl√©s d'exclusion (alimentation animale, etc.)
    exclusion_keywords = [
        "feed", "animal feed", "alimentation animale", "aliment pour animaux", "aliments pour animaux",
        "pet food", "nourriture pour animaux", "food for animals", "animal nutrition",
        "cosmetic", "cosm√©tique", "cosmetics", "cosm√©tiques",
        "medical device", "dispositif m√©dical", "pharmaceutical", "pharmaceutique", "drug",
        "fertilizer", "fertilisant", "pesticide application", "agricultural chemicals"
    ]
    
    # Mots-cl√©s de recherche fondamentale (moins prioritaires)
    research_keywords = [
        "in vitro", "in vivo", "laboratory study", "√©tude de laboratoire", "recherche fondamentale",
        "basic research", "theoretical", "th√©orique", "model", "mod√®le", "simulation"
    ]
    
    # Identifier les types de produits dans le profil utilisateur
    user_product_types = []
    for product_type in product_keywords.keys():
        if product_type in context_lower:
            user_product_types.append(product_type)
    
    # Si "autre" est dans le profil, on est moins restrictif
    if "autre" in user_product_types:
        less_restrictive = True
    else:
        less_restrictive = False
    
    filtered_articles = []
    
    for article in evaluated_articles:
        title_lower = article['Titre'].lower()
        summary_lower = article['R√©sum√©'].lower()
        article_text = f"{title_lower} {summary_lower}"
        
        # Calcul de p√©nalit√©s
        penalty = 0
        reasons = []
        
        # V√©rification des mots-cl√©s d'exclusion STRICTE
        exclusion_found = []
        for keyword in exclusion_keywords:
            if keyword in article_text:
                exclusion_found.append(keyword)
        
        if exclusion_found:
            penalty += 60  # P√©nalit√© tr√®s lourde
            reasons.append(f"Exclusion d√©tect√©e: {', '.join(exclusion_found[:2])}")
        
        # V√©rification de la correspondance avec les types de produits
        if not less_restrictive and user_product_types:
            product_match_found = False
            matched_products = []
            
            for user_product_type in user_product_types:
                if user_product_type in product_keywords:
                    keywords = product_keywords[user_product_type]
                    for keyword in keywords:
                        if keyword in article_text:
                            product_match_found = True
                            matched_products.append(keyword)
                            break
                    if product_match_found:
                        break
            
            # Si aucune correspondance trouv√©e, p√©nalit√© importante
            if not product_match_found:
                penalty += 40
                reasons.append("Aucune correspondance type de produit")
            elif matched_products:
                reasons.append(f"Produit d√©tect√©: {matched_products[0]}")
        
        # V√©rification recherche fondamentale
        research_found = any(keyword in article_text for keyword in research_keywords)
        if research_found:
            penalty += 15
            reasons.append("Recherche fondamentale")
        
        # Application des p√©nalit√©s
        original_score = article['Score']
        article['Score'] = max(0, original_score - penalty)
        
        # Mise √† jour de l'√©valuation avec les raisons
        if reasons:
            article['√âvaluation de la Pertinence'] += f" [FILTRAGE: {'; '.join(reasons)}]"
        
        # Log des modifications importantes
        if penalty > 30:
            article['√âvaluation de la Pertinence'] += f" [SCORE: {original_score}‚Üí{article['Score']}]"
        
        # Seuil d'exclusion apr√®s filtrage
        if article['Score'] >= 25:  # Seuil minimum apr√®s filtrage
            filtered_articles.append(article)
    
    return filtered_articles

@st.cache_data(ttl=1800, show_spinner="R√©cup√©ration RSS...")
def fetch_rss_feed(url: str) -> List[Dict]:
    """R√©cup√®re les entr√©es RSS avec gestion d'erreur am√©lior√©e."""
    try:
        # Headers pour √©viter les blocages
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        # Tentative avec requests d'abord pour les URLs probl√©matiques
        if 'health.belgium.be' in url:
            try:
                response = requests.get(url, headers=headers, timeout=10)
                response.raise_for_status()
                feed = feedparser.parse(response.content)
            except Exception as e:
                st.warning(f"Erreur requests pour {url}, tentative feedparser direct: {e}")
                feed = feedparser.parse(url)
        else:
            feed = feedparser.parse(url)
        
        if feed.bozo and feed.bozo_exception:
            st.warning(f"Probl√®me de parsing pour {url}: {feed.bozo_exception}")
        
        return feed.entries
        
    except Exception as e:
        st.error(f"Erreur RSS {url}: {e}")
        return []

def fetch_all_articles(feeds: Dict[str, str], start_date: datetime.date, end_date: datetime.date, clean_html: bool = True) -> List[Dict]:
    """R√©cup√®re tous les articles en parall√®le avec extraction optimis√©e du contenu."""
    all_articles = []
    failed_feeds = []
    
    # R√©cup√©ration de l'option de formatage depuis session_state ou valeur par d√©faut
    preserve_formatting = st.session_state.get('preserve_formatting', True)
    
    with st.spinner("R√©cup√©ration des flux RSS..."):
        progress_bar = st.progress(0)
        
        for idx, (source_name, url) in enumerate(feeds.items()):
            try:
                with st.spinner(f"R√©cup√©ration de {source_name}..."):
                    entries = fetch_rss_feed(url)
                    
                    if not entries:
                        st.warning(f"Aucune entr√©e trouv√©e pour {source_name}")
                        if source_name not in failed_feeds: # Avoid duplicates
                            failed_feeds.append(source_name)
                        continue
                
                for entry in entries:
                    try:
                        published_date = None
                        
                        # Gestion am√©lior√©e des dates
                        if hasattr(entry, 'published_parsed') and entry.published_parsed:
                            published_date = datetime(*entry.published_parsed[:6]).date()
                        elif hasattr(entry, 'updated_parsed') and entry.updated_parsed:
                            published_date = datetime(*entry.updated_parsed[:6]).date()
                        elif hasattr(entry, 'published'):
                            try:
                                # Essayer diff√©rents formats de date
                                for fmt in ['%a, %d %b %Y %H:%M:%S %Z', '%a, %d %b %Y %H:%M:%S %z', '%Y-%m-%d']:
                                    try:
                                        published_date = datetime.strptime(entry.published, fmt).date()
                                        break
                                    except ValueError:
                                        continue
                            except Exception as e_parse_str_date:
                                # If parsing fails, default to now, and optionally log or inform user
                                # For now, just using a default. A debug message could be added.
                                # st.sidebar.caption(f"Debug: Date parse error for '{entry.get('title', 'Unknown title')}', used current date. Error: {e_parse_str_date}")
                                published_date = datetime.now().date()
                        
                        # Si pas de date trouv√©e, utiliser la date actuelle
                        if not published_date:
                            published_date = datetime.now().date()
                        
                        if start_date <= published_date <= end_date:
                            # Extraction optimis√©e du contenu
                            raw_content = extract_content_from_entry(entry)
                            
                            # Validation du contenu
                            if not raw_content or len(raw_content.strip()) < 10:
                                raw_content = getattr(entry, 'title', 'Contenu non disponible')
                            
                            # Nettoyage HTML optionnel
                            if clean_html:
                                summary = clean_html_content(raw_content, preserve_basic_formatting=preserve_formatting)
                            else:
                                summary = raw_content
                            
                            # Validation finale
                            if not summary or len(summary.strip()) < 5:
                                summary = "R√©sum√© non disponible"
                            
                            all_articles.append({
                                "source": source_name,
                                "title": getattr(entry, 'title', 'Titre non disponible'),
                                "summary": summary,
                                "raw_content": raw_content,
                                "link": getattr(entry, 'link', '#'),
                                "published": published_date
                            })
                            
                    except Exception as e:
                        st.warning(f"Erreur lors du traitement d'un article de {source_name}: {e}")
                        continue
                        
                progress_bar.progress((idx + 1) / len(feeds))
                
            except Exception as e:
                st.error(f"Erreur lors de la r√©cup√©ration de {source_name}: {e}")
                if source_name not in failed_feeds: # Avoid duplicates
                    failed_feeds.append(source_name)
                continue
    
    st.success(f"‚úÖ {len(all_articles)} articles r√©cup√©r√©s au total")

    if failed_feeds:
        unique_failed_feeds = sorted(list(set(failed_feeds)))
        st.warning(f"‚ö†Ô∏è Probl√®mes rencontr√©s avec les flux suivants : {', '.join(unique_failed_feeds)}. Certains articles de ces sources pourraient manquer.")

    return all_articles

# --- Interface Streamlit optimis√©e ---

st.set_page_config(
    page_title="Veille R√©glementaire Food Safety", 
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("üîç Veille R√©glementaire - S√©curit√© Alimentaire")
st.markdown("*Application optimis√©e pour consultants et auditeurs food safety*")
st.markdown("‚ú® **Nouveau** : √âvaluation ultra-stricte de la pertinence + Filtrage avanc√© par type de produit")

# Sidebar pour la configuration
with st.sidebar:
    st.header("‚öôÔ∏è Configuration")
    
    # Seuil de pertinence
    min_pertinence_score = st.slider(
        "Score minimum de pertinence", 
        min_value=0, 
        max_value=100, 
        value=60,
        help="Articles avec un score inf√©rieur seront filtr√©s"
    )
    
    # Nombre max d'articles
    max_articles = st.selectbox(
        "Nombre maximum d'articles √† √©valuer",
        [10, 20, 50, 100],
        index=1
    )
    
    # Options de filtrage strict
    st.subheader("üéØ Filtrage Strict")
    
    enable_strict_filtering = st.checkbox(
        "Activer le filtrage strict par type de produit",
        value=True,
        help="Applique des p√©nalit√©s automatiques pour les articles non-correspondants"
    )
    
    exclude_research = st.checkbox(
        "Exclure la recherche fondamentale",
        value=True,
        help="P√©nalise les articles de recherche pure sans application pratique"
    )
    
    # Options de parsing
    st.subheader("üîß Options de parsing")
    
    st.session_state['clean_html'] = st.checkbox(
        "Nettoyer le HTML des r√©sum√©s",
        value=True,
        help="Convertit le HTML en texte lisible (recommand√© pour Health BE)"
    )
    
    st.session_state['preserve_formatting'] = st.checkbox(
        "Pr√©server le formatage de base",
        value=True,
        help="Garde les paragraphes et listes lors du nettoyage HTML"
    )
    
    # Option de traduction
    st.session_state['translate_to_french'] = st.checkbox(
        "üá´üá∑ Traduire le contenu en fran√ßais",
        value=False,
        help="Traduit automatiquement les titres et r√©sum√©s en fran√ßais (utilise l'API Groq)"
    )
    
    # Information sur l'extraction de contenu
    with st.expander("‚ÑπÔ∏è Filtrage & Extraction"):
        st.markdown("""
        **üéØ Filtrage Ultra-Strict:**
        - Exclusion automatique : alimentation animale, cosm√©tiques
        - Correspondance exacte types de produits requis
        - P√©nalit√©s pour recherche fondamentale
        
        **üìä Extraction de contenu:**
        1. `content:encoded` (plus d√©taill√©, notamment Health BE)
        2. `summary/description` (fallback standard)
        3. `title` (fallback minimal)
        
        **üá´üá∑ Traduction** : Les articles EFSA/EU (en anglais) peuvent √™tre traduits automatiquement
        """)
    
# --- Profil utilisateur (simplifi√©) ---
with st.expander("üè¢ Profil d'Activit√©", expanded=True):
    col1, col2 = st.columns(2)
    
    with col1:
        selected_product_types = st.multiselect(
            "Types de Produits",
            PRODUCT_TYPES,
            default=["Autre"],
            help="‚ö†Ô∏è S√©lection tr√®s importante pour le filtrage strict!"
        )
        
        selected_risk_types = st.multiselect(
            "Types de Risques",
            RISK_TYPES,
            default=["Microbiologique", "Chimique"]
        )
    
    with col2:
        selected_markets = st.multiselect(
            "March√©s Cibles",
            MARKETS,
            default=["UE", "France"]
        )
        
        main_concerns = st.text_area(
            "Pr√©occupations Sp√©cifiques",
            placeholder="Ex: PFAS, Listeria, nouvelles r√©glementations EU...",
            height=100
        )

# Cr√©ation du contexte utilisateur
user_context = f"""
Types de Produits: {', '.join(selected_product_types)}
Types de Risques: {', '.join(selected_risk_types)}
March√©s: {', '.join(selected_markets)}
Pr√©occupations: {main_concerns}
Profil: Consultant/Auditeur en s√©curit√© alimentaire europ√©enne
"""

# --- Configuration p√©riode et API ---
col1, col2, col3 = st.columns([2, 2, 3])

with col1:
    start_date = st.date_input("üìÖ Date de D√©but", datetime.now() - timedelta(days=7))

with col2:
    end_date = st.date_input("üìÖ Date de Fin", datetime.now())

with col3:
    groq_api_key = os.getenv("GROQ_API_KEY") or st.secrets.get("GROQ_API_KEY")
    if not groq_api_key:
        groq_api_key = st.text_input("üîë Cl√© API Groq", type="password", 
                                   help="N√©cessaire pour l'√©valuation de pertinence")

# --- Lancement de la veille ---
if st.button("üöÄ Lancer la Veille", type="primary", use_container_width=True, disabled=not groq_api_key):
    if not groq_api_key:
        st.error("Cl√© API Groq requise pour l'√©valuation de pertinence")
        st.stop()
    
    if start_date > end_date:
        st.error("La date de fin doit √™tre post√©rieure √† la date de d√©but")
        st.stop()
    
    # R√©cup√©ration des articles
    all_articles = fetch_all_articles(FRENCH_EU_RSS_FEEDS, start_date, end_date, st.session_state.get('clean_html', True))
    
    if not all_articles:
        st.warning("Aucun article trouv√© dans la p√©riode sp√©cifi√©e")
        st.stop()
    
    # Limitation du nombre d'articles √† √©valuer
    all_articles = all_articles[:max_articles]
    
    # Message informatif sur la traduction
    translate_to_french = st.session_state.get('translate_to_french', False)
    if translate_to_french:
        st.info(f"üá´üá∑ **Mode traduction activ√©** : Les titres et r√©sum√©s en anglais seront traduits automatiquement")
        st.info("‚û°Ô∏è V√©rifiez la sidebar pour les d√©tails de traduction en temps r√©el")
    
    st.info(f"üîç √âvaluation de {len(all_articles)} articles avec crit√®res ultra-stricts...")
    
    # √âvaluation des articles avec traduction optionnelle
    evaluator = ArticleEvaluator(groq_api_key)
    evaluated_articles = []
    
    progress_bar = st.progress(0)
    progress_text = st.empty()
    
    # Option de traduction et conteneur de debug
    translate_to_french = st.session_state.get('translate_to_french', False)
    translation_debug = None
    
    if translate_to_french:
        # Cr√©er un conteneur de debug dans la sidebar
        with st.sidebar:
            st.markdown("**üîç Debug Traduction en cours:**")
            translation_debug = st.empty()
    
    for idx, article in enumerate(all_articles):
        progress_text.text(f"√âvaluation {idx+1}/{len(all_articles)}: {article['source']}")
        
        # Traduction optionnelle AVANT √©valuation
        current_title = article['title']
        current_summary = article['summary']
        translation_performed_for_article = False # Pour marquer si au moins un des champs a √©t√© r√©ellement chang√©
        
        if translate_to_french:
            progress_text.text(f"Traduction {idx+1}/{len(all_articles)}: {article['source']}")
            
            original_title = article['title']
            original_summary = article['summary']

            translated_title_text, title_translation_attempted = evaluator.translate_to_french(original_title, "titre")
            summary_translation_text, summary_translation_attempted = evaluator.translate_to_french(original_summary, "r√©sum√©")

            title_changed = (translated_title_text != original_title)
            summary_changed = (summary_translation_text != original_summary)

            current_title = translated_title_text
            current_summary = summary_translation_text
            
            if title_changed or summary_changed:
                translation_performed_for_article = True

            # Debug info dans la sidebar
            if translation_debug is not None:
                # Titre
                if not title_translation_attempted:
                    translation_debug.info(f"‚ÑπÔ∏è Titre Art.{idx+1} ({article['source']}): Non traduit (d√©j√† FR)")
                elif title_changed:
                    translation_debug.success(f"‚úÖ Titre Art.{idx+1} ({article['source']}): Traduit")
                else: # Tentative mais pas de changement ou √©chec qualit√©
                    translation_debug.warning(f"‚ö†Ô∏è Titre Art.{idx+1} ({article['source']}): Original conserv√© (trad. insatisfaisante/√©chec)")

                # R√©sum√©
                if not summary_translation_attempted:
                    translation_debug.info(f"‚ÑπÔ∏è R√©sum√© Art.{idx+1} ({article['source']}): Non traduit (d√©j√† FR)")
                elif summary_changed:
                    translation_debug.success(f"‚úÖ R√©sum√© Art.{idx+1} ({article['source']}): Traduit")
                else: # Tentative mais pas de changement ou √©chec qualit√©
                    translation_debug.warning(f"‚ö†Ô∏è R√©sum√© Art.{idx+1} ({article['source']}): Original conserv√© (trad. insatisfaisante/√©chec)")

        progress_text.text(f"√âvaluation {idx+1}/{len(all_articles)}: {article['source']}")
        
        # √âvaluation avec le contenu (possiblement traduit)
        pertinence_level, evaluation_summary, score = evaluator.evaluate_pertinence(
            current_title,
            current_summary,
            user_context
        )
        
        # Filtrage bas√© sur le score minimum
        if score >= min_pertinence_score:
            evaluated_articles.append({
                "Source": article['source'],
                "Titre": current_title,  # Titre possiblement traduit
                "R√©sum√©": current_summary,  # R√©sum√© possiblement traduit
                "Titre Original": article['title'],  # Garde l'original pour r√©f√©rence
                "R√©sum√© Original": article['summary'],  # Garde l'original pour r√©f√©rence
                "Lien": article['link'],
                "Date de Publication": article['published'].strftime('%Y-%m-%d'),
                "Niveau de Pertinence": pertinence_level,
                "Score": score,
                "√âvaluation de la Pertinence": evaluation_summary,
                "raw_content": article.get('raw_content', ''),
                "Traduit": translation_performed_for_article # Utilise le nouveau flag
            })
        
        progress_bar.progress((idx + 1) / len(all_articles))
    
    progress_text.empty()
    progress_bar.empty()
    
    # Nettoyage du debug de traduction
    if translate_to_french and translation_debug is not None:
        translation_debug.empty()
    
    # NOUVEAU: Filtrage suppl√©mentaire bas√© sur les mots-cl√©s
    if evaluated_articles and enable_strict_filtering:
        articles_before_filtering = len(evaluated_articles)
        st.info("üéØ Application du filtrage strict bas√© sur les types de produits...")
        evaluated_articles = apply_additional_filtering(evaluated_articles, user_context)
        
        # Re-filtrage bas√© sur le score minimum apr√®s ajustements
        evaluated_articles = [a for a in evaluated_articles if a['Score'] >= min_pertinence_score]
        
        articles_after_filtering = len(evaluated_articles)
        if articles_before_filtering != articles_after_filtering:
            st.warning(f"‚ö†Ô∏è Filtrage strict : {articles_before_filtering - articles_after_filtering} articles suppl√©mentaires filtr√©s")
    
    # Affichage des r√©sultats
    if evaluated_articles:
        # Tri par score d√©croissant
        evaluated_articles.sort(key=lambda x: x['Score'], reverse=True)
        
        st.success(f"‚úÖ {len(evaluated_articles)} articles pertinents trouv√©s apr√®s filtrage strict (score ‚â• {min_pertinence_score})")
        
        # M√©triques am√©lior√©es
        col1, col2, col3, col4, col5 = st.columns(5)
        
        score_stats = [a['Score'] for a in evaluated_articles]
        with col1:
            st.metric("Score Moyen", f"{sum(score_stats)/len(score_stats):.1f}/100")
        with col2:
            very_pertinent = len([a for a in evaluated_articles if a['Score'] >= 80])
            st.metric("Tr√®s Pertinents", very_pertinent)
        with col3:
            moderate_pertinent = len([a for a in evaluated_articles if 60 <= a['Score'] < 80])
            st.metric("Mod√©r√©ment Pertinents", moderate_pertinent)
        with col4:
            st.metric("Score Max", f"{max(score_stats)}/100")
        with col5:
            translated_count = len([a for a in evaluated_articles if a.get('Traduit', False)])
            st.metric("Traduits", f"{translated_count}/{len(evaluated_articles)}")
        
        # AFFICHAGE SIMPLE - AUCUN data_editor !
        st.subheader("üìä Articles S√©lectionn√©s")
        
        # 1. Vue d'ensemble avec tableau simple
        st.markdown("### üìã Vue d'ensemble")
        
        # Pr√©paration simple des donn√©es
        simple_data = []
        for article in evaluated_articles:
            score_visual = f"‚≠ê {article['Score']}/100 " + ("üü¢" if article['Score'] >= 80 else "üü°" if article['Score'] >= 60 else "üü†")
            lien_status = "üîó Disponible" if article['Lien'] != '#' else "‚ùå Indisponible"
            
            # Indicateur de traduction
            title_display = article['Titre'][:80] + ("..." if len(article['Titre']) > 80 else "")
            if article.get('Traduit', False):
                title_display = f"üá´üá∑ {title_display}"
            
            simple_data.append({
                'Source': article['Source'],
                'Titre': title_display,
                'Score': score_visual,
                'Date': article['Date de Publication'],
                'Lien': lien_status
            })
        
        # Affichage tableau simple
        simple_df = pd.DataFrame(simple_data)
        st.dataframe(simple_df, use_container_width=True)
        
        # 2. S√©lection pour export
        st.markdown("### üì• S√©lection pour Export")
        
        options_for_export = []
        for idx, article in enumerate(evaluated_articles):
            # Ajoute un indicateur de traduction dans le label
            translation_indicator = " üá´üá∑" if article.get('Traduit', False) else ""
            label = f"‚≠ê{article['Score']} - {article['Source']} - {article['Titre'][:50]}...{translation_indicator}"
            options_for_export.append((idx, label))
        
        selected_indices = st.multiselect(
            "S√©lectionnez les articles √† exporter :",
            options=[opt[0] for opt in options_for_export],
            format_func=lambda x: next(opt[1] for opt in options_for_export if opt[0] == x),
            default=list(range(min(5, len(options_for_export))))
        )
        
        # 3. Affichage d√©taill√©
        if selected_indices:
            st.markdown(f"### üìñ D√©tails des {len(selected_indices)} articles s√©lectionn√©s")
            
            for idx in selected_indices:
                if idx < len(evaluated_articles):
                    article = evaluated_articles[idx]
                    
                    with st.expander(f"‚≠ê {article['Score']}/100 - {article['Source']} - {article['Titre'][:60]}..."):
                        col1, col2 = st.columns([3, 1])
                        
                        with col1:
                            # Affichage du titre avec indicateur de traduction
                            if article.get('Traduit', False):
                                st.markdown(f"**üì∞ Titre (üá´üá∑ traduit) :** {article['Titre']}")
                                
                                # Utilisation d'un toggle button au lieu d'un expander imbriqu√©
                                show_original_title = st.checkbox("üëÅÔ∏è Voir titre original", key=f"title_orig_{idx}")
                                if show_original_title:
                                    st.info(f"**üî§ Titre original :** {article.get('Titre Original', 'N/A')}")
                            else:
                                st.markdown(f"**üì∞ Titre :** {article['Titre']}")
                            
                            # Affichage du r√©sum√© avec indicateur de traduction
                            if article.get('Traduit', False):
                                st.markdown(f"**üìù R√©sum√© (üá´üá∑ traduit) :**")
                                st.write(article['R√©sum√©'])
                                
                                # Utilisation d'un toggle button au lieu d'un expander imbriqu√©
                                show_original_summary = st.checkbox("üëÅÔ∏è Voir r√©sum√© original", key=f"summary_orig_{idx}")
                                if show_original_summary:
                                    st.info(f"**üìù R√©sum√© original :**")
                                    st.write(article.get('R√©sum√© Original', 'N/A'))
                            else:
                                st.markdown(f"**üìù R√©sum√© :**")
                                st.write(article['R√©sum√©'])
                            
                            st.markdown(f"**üîç √âvaluation :**")
                            st.write(article['√âvaluation de la Pertinence'])
                        
                        with col2:
                            st.markdown(f"**üì° Source :** {article['Source']}")
                            st.markdown(f"**‚≠ê Score :** {article['Score']}/100")
                            st.markdown(f"**üìÖ Date :** {article['Date de Publication']}")
                            
                            if article['Lien'] != '#':
                                st.markdown(f"**[üîó Ouvrir l'article]({article['Lien']})**")
                            else:
                                st.markdown("**‚ùå Lien indisponible**")
        else:
            st.info("S√©lectionnez des articles ci-dessus pour voir les d√©tails")
        
        # 4. Debug avanc√©
        if st.sidebar.checkbox("üî¨ Mode Debug - Afficher contenu brut"):
            st.markdown("### üî¨ Comparaison Contenu Nettoy√© vs Brut")
            
            debug_article_idx = st.selectbox(
                "S√©lectionnez un article pour le debug :",
                range(len(evaluated_articles)),
                format_func=lambda x: f"{evaluated_articles[x]['Source']} - {evaluated_articles[x]['Titre'][:50]}..."
            )
            
            if debug_article_idx < len(evaluated_articles):
                article = evaluated_articles[debug_article_idx]
                
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("**üìù Contenu Nettoy√©:**")
                    st.text_area("", article['R√©sum√©'], height=200, key="clean_content_debug")
                
                with col2:
                    st.markdown("**üîß Contenu Brut (HTML):**")
                    raw_content = article.get('raw_content', 'Non disponible')
                    st.text_area("", raw_content, height=200, key="raw_content_debug")
        
        # 5. Statistiques de filtrage
        if st.sidebar.checkbox("üìä Statistiques de filtrage"):
            st.markdown("### üìä Analyse du Filtrage")
            
            # Analyse des √©valuations contenant des alertes de filtrage
            filtered_evaluations = [a for a in evaluated_articles if "[FILTRAGE:" in a['√âvaluation de la Pertinence']]
            
            if filtered_evaluations:
                st.info(f"üéØ {len(filtered_evaluations)} articles ont subi un filtrage suppl√©mentaire")
                
                # Extraction des raisons de filtrage
                filter_reasons = {}
                for article in filtered_evaluations:
                    eval_text = article['√âvaluation de la Pertinence']
                    if "[FILTRAGE:" in eval_text:
                        reason_part = eval_text.split("[FILTRAGE:")[1].split("]")[0]
                        reasons = reason_part.split(";")
                        for reason in reasons:
                            reason = reason.strip()
                            if reason:
                                filter_reasons[reason] = filter_reasons.get(reason, 0) + 1
                
                if filter_reasons:
                    st.markdown("**Raisons de filtrage :**")
                    for reason, count in sorted(filter_reasons.items(), key=lambda x: x[1], reverse=True):
                        st.write(f"- {reason}: {count} articles")
            else:
                st.success("‚úÖ Aucun article n'a n√©cessit√© de filtrage suppl√©mentaire")
        
        # T√©l√©chargement
        if len(evaluated_articles) > 0:
            st.subheader("üíæ T√©l√©chargement")
            
            col1, col2, col3 = st.columns(3)
            
            # Pr√©paration donn√©es export (nettoie les colonnes techniques)
            if selected_indices:
                selected_articles_data = [evaluated_articles[i] for i in selected_indices if i < len(evaluated_articles)]
                # Nettoyage pour export
                clean_articles = []
                for article in selected_articles_data:
                    clean_article = {
                        'Source': article['Source'],
                        'Titre': article['Titre'],
                        'R√©sum√©': article['R√©sum√©'],
                        'Lien': article['Lien'],
                        'Date de Publication': article['Date de Publication'],
                        'Niveau de Pertinence': article['Niveau de Pertinence'],
                        'Score': article['Score'],
                        '√âvaluation de la Pertinence': article['√âvaluation de la Pertinence']
                    }
                    # Ajoute les versions originales si traduit
                    if article.get('Traduit', False):
                        clean_article['Titre Original'] = article.get('Titre Original', '')
                        clean_article['R√©sum√© Original'] = article.get('R√©sum√© Original', '')
                        clean_article['Traduit'] = 'Oui'
                    else:
                        clean_article['Traduit'] = 'Non'
                    clean_articles.append(clean_article)
                
                export_df = pd.DataFrame(clean_articles)
                st.success(f"üìå {len(selected_articles_data)} articles s√©lectionn√©s pour l'export")
            else:
                # M√™me nettoyage pour tous les articles
                clean_articles = []
                for article in evaluated_articles:
                    clean_article = {
                        'Source': article['Source'],
                        'Titre': article['Titre'],
                        'R√©sum√©': article['R√©sum√©'],
                        'Lien': article['Lien'],
                        'Date de Publication': article['Date de Publication'],
                        'Niveau de Pertinence': article['Niveau de Pertinence'],
                        'Score': article['Score'],
                        '√âvaluation de la Pertinence': article['√âvaluation de la Pertinence']
                    }
                    if article.get('Traduit', False):
                        clean_article['Titre Original'] = article.get('Titre Original', '')
                        clean_article['R√©sum√© Original'] = article.get('R√©sum√© Original', '')
                        clean_article['Traduit'] = 'Oui'
                    else:
                        clean_article['Traduit'] = 'Non'
                    clean_articles.append(clean_article)
                
                export_df = pd.DataFrame(clean_articles)
                st.info("üìå Aucune s√©lection - tous les articles seront export√©s")
            
            with col1:
                csv_data = export_df.to_csv(index=False).encode('utf-8')
                st.download_button(
                    label="üì• T√©l√©charger CSV",
                    data=csv_data,
                    file_name=f"veille_food_safety_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
                    mime="text/csv",
                    use_container_width=True
                )
            
            with col2:
                excel_buffer = BytesIO()
                with pd.ExcelWriter(excel_buffer, engine='xlsxwriter') as writer:
                    export_df.to_excel(writer, sheet_name='Veille Food Safety', index=False)
                
                excel_buffer.seek(0)
                st.download_button(
                    label="üì• T√©l√©charger Excel",
                    data=excel_buffer,
                    file_name=f"veille_food_safety_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True
                )
            
            with col3:
                if selected_indices:
                    scores = [evaluated_articles[i]['Score'] for i in selected_indices if i < len(evaluated_articles)]
                    if scores:
                        avg_score = sum(scores) / len(scores)
                        st.metric("Score Moyen S√©lection", f"{avg_score:.1f}/100")
                else:
                    st.info("Aucune s√©lection active")
    
    else:
        st.warning(f"‚ùå Aucun article avec un score ‚â• {min_pertinence_score} trouv√© apr√®s filtrage strict. Essayez de :")
        st.markdown("""
        - R√©duire le seuil de pertinence
        - D√©sactiver le filtrage strict
        - √âlargir les types de produits (ajouter "Autre")
        - V√©rifier la correspondance avec votre profil
        """)

# Footer am√©lior√©
st.markdown("---")
st.markdown("*D√©velopp√© pour les professionnels de la s√©curit√© alimentaire europ√©enne*")
st.markdown("üéØ **Version 2.0** : Filtrage ultra-strict + Traduction automatique + Export optimis√©")
