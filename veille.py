import streamlit as st
import feedparser
import requests
from datetime import datetime, timedelta
import os
from groq import Groq
import pandas as pd
from io import BytesIO
import concurrent.futures
from typing import List, Dict, Tuple
import time
import re
from html import unescape

# --- Configuration ---
PRODUCT_TYPES = ["Produits laitiers", "Viande", "Produits frais", "Produits de boulangerie", "Boissons", "Aliments transform√©s", "Autre"]
RISK_TYPES = ["Microbiologique", "Chimique", "Physique", "Allerg√®ne", "Fraude", "Autre"]
MARKETS = ["UE", "US", "Canada", "Royaume-Uni", "France", "International", "Autre"]

# Flux RSS optimis√©s avec gestion sp√©ciale pour Health BE
FRENCH_EU_RSS_FEEDS = {
    "EFSA": "https://www.efsa.europa.eu/en/all/rss",
    "EU Food Safety": "https://food.ec.europa.eu/node/2/rss_en",
    "ANSES": "https://www.anses.fr/fr/flux-actualites.rss",
    "Health BE": "https://www.health.belgium.be/fr/rss/news.xml",
}

FOOD_SAFETY_KEYWORDS = [
    "rappel", "contamination", "allerg√®ne", "pathog√®ne", "hygi√®ne", "r√©glementation",
    "norme", "conformit√©", "audit", "inspection", "danger", "√©valuation des risques",
    "maladie d'origine alimentaire", "tra√ßabilit√©", "HACCP", "GFSI", "pesticide", "additif",
    "emballage", "√©tiquetage", "microbiologie", "toxicologie", "nouvel aliment", "fraude alimentaire"
]

# Configuration de pertinence
PERTINENCE_LEVELS = {
    "Tr√®s pertinent": {"score": 3, "color": "üü¢", "min_threshold": 80},
    "Mod√©r√©ment pertinent": {"score": 2, "color": "üü°", "min_threshold": 60},
    "Peu pertinent": {"score": 1, "color": "üü†", "min_threshold": 40},
    "Non pertinent": {"score": 0, "color": "üî¥", "min_threshold": 0}
}

# --- Classes et fonctions optimis√©es ---

def clean_html_content(html_content: str, preserve_basic_formatting: bool = True) -> str:
    """Nettoie le contenu HTML pour l'affichage et l'analyse."""
    if not html_content:
        return ""
    
    # Decode HTML entities
    cleaned = unescape(html_content)
    
    if preserve_basic_formatting:
        # Remplace les balises de paragraphe par des retours √† la ligne
        cleaned = re.sub(r'</?p[^>]*>', '\n', cleaned)
        cleaned = re.sub(r'<br[^>]*/?>', '\n', cleaned)
        # Garde les listes avec des tirets
        cleaned = re.sub(r'<li[^>]*>', '- ', cleaned)
        cleaned = re.sub(r'</li>', '\n', cleaned)
        # Supprime toutes les autres balises HTML
        cleaned = re.sub(r'<[^>]+>', '', cleaned)
    else:
        # Supprime toutes les balises HTML
        cleaned = re.sub(r'<[^>]+>', '', cleaned)
    
    # Nettoie les espaces multiples et retours √† la ligne
    cleaned = re.sub(r'\n\s*\n', '\n\n', cleaned)  # Double retours √† la ligne max
    cleaned = re.sub(r'[ \t]+', ' ', cleaned)  # Espaces multiples
    cleaned = cleaned.strip()
    
    return cleaned

def extract_content_from_entry(entry) -> str:
    """Extrait le meilleur contenu disponible d'une entr√©e RSS."""
    content = ""
    
    # 1. Priorit√© : content:encoded (plus d√©taill√©)
    if hasattr(entry, 'content') and entry.content:
        try:
            content = entry.content[0].value
        except (IndexError, AttributeError):
            pass
    
    # 2. Fallback : summary/description
    if not content and hasattr(entry, 'summary'):
        content = entry.summary
    
    # 3. Fallback final : title
    if not content:
        content = entry.title
    
    return content

class ArticleEvaluator:
    GROQ_MODEL = "llama3-8b-8192"
    MAX_TOKENS_TRANSLATE = 500
    MAX_TOKENS_EVALUATE = 400

    def __init__(self, groq_api_key: str):
        self.client = Groq(api_key=groq_api_key) if groq_api_key else None
    
    def translate_to_french(self, text: str, content_type: str = "texte") -> Tuple[str, bool]:
        """
        Traduit un texte en fran√ßais en utilisant Groq.
        Retourne un tuple: (texte_resultat, bool_tentative_traduction)
        bool_tentative_traduction est True si une requ√™te API a √©t√© faite, False sinon.
        """
        translation_attempted = False
        if not self.client or not text or len(text.strip()) < 3:
            return text, translation_attempted
        
        # D√©tection plus robuste de l'anglais
        english_words = ['the', 'and', 'of', 'in', 'to', 'for', 'with', 'on', 'at', 'by', 'from', 'as', 'is', 'are', 'was', 'were', 'been', 'have', 'has', 'had', 'will', 'would', 'could', 'should', 'may', 'might', 'can', 'must']
        text_lower = text.lower()
        
        # Compte les mots anglais
        word_count = len(text.split())
        english_count = sum(1 for word in english_words if f' {word} ' in f' {text_lower} ' or text_lower.startswith(f'{word} ') or text_lower.endswith(f' {word}'))
        
        # Si moins de 20% de mots anglais d√©tect√©s, probablement d√©j√† en fran√ßais
        if word_count > 0 and (english_count / word_count) < 0.2:
            return text, translation_attempted # Pas de tentative de traduction
        
        translation_attempted = True # Marquer comme tentative si on passe l'heuristique
        try:
            prompt = f"""
            Traduisez ce {content_type} scientifique en fran√ßais professionnel.
            Gardez tous les termes techniques, noms d'esp√®ces, codes de r√©f√©rence, et acronymes en version originale.
            
            IMPORTANT : R√©pondez UNIQUEMENT avec la traduction fran√ßaise, rien d'autre.
            
            Texte √† traduire :
            {text}
            """
            
            response = self.client.chat.completions.create(
                messages=[{"role": "user", "content": prompt}],
                model=self.GROQ_MODEL,
                temperature=0.0,  # Plus d√©terministe
                max_tokens=self.MAX_TOKENS_TRANSLATE,
            )
            
            translated = response.choices[0].message.content.strip()
            
            # V√©rifie que la traduction n'est pas vide et diff√©rente de l'original
            if translated and len(translated) > 10 and translated != text:
                return translated, translation_attempted
            else:
                # La traduction a √©chou√© ou n'est pas satisfaisante
                return text, translation_attempted
            
        except Exception as e:
            st.warning(f"Erreur de traduction pour {content_type}: {e}. Veuillez v√©rifier votre cl√© API Groq et votre connexion r√©seau.")
            return text, translation_attempted # Retourne l'original mais signale la tentative
        
    def evaluate_pertinence(self, article_title: str, article_summary: str, user_context: str) -> Tuple[str, str, int]:
        """√âvalue la pertinence avec un score num√©rique pour un meilleur filtrage."""
        if not self.client:
            return "Non pertinent", "Cl√© API manquante", 0

        prompt = f"""
        Vous √™tes un expert en s√©curit√© alimentaire. √âvaluez la pertinence de cet article pour un professionnel avec le profil suivant.

        PROFIL UTILISATEUR:
        {user_context}

        ARTICLE √Ä √âVALUER:
        Titre: {article_title}
        R√©sum√©: {article_summary}

        CRIT√àRES D'√âVALUATION STRICTS:
        
        ‚≠ê Tr√®s pertinent (80-100): 
        - Impact DIRECT sur les types de produits mentionn√©s dans le profil
        - R√©glementation APPLICABLE aux march√©s sp√©cifi√©s
        - Risque majeur pour l'activit√© d√©clar√©e
        
        ‚≠ê Mod√©r√©ment pertinent (60-79):
        - Lien indirect avec les produits/risques/march√©s du profil
        - √âvolution r√©glementaire g√©n√©rale mais applicable
        - Veille concurrentielle pertinente
        
        ‚≠ê Peu pertinent (40-59):
        - Information g√©n√©rale sur l'industrie alimentaire
        - Contexte r√©glementaire large
        
        ‚≠ê Non pertinent (0-39):
        - Hors sujet par rapport au profil
        - Concerne d'autres secteurs (ex: alimentation animale vs produits pour humains)
        - G√©ographie non pertinente
        - Types de produits/risques non couverts par le profil
        
        ATTENTION PARTICULI√àRE:
        - Si l'article concerne l'alimentation animale et le profil les produits pour humains ‚Üí Score faible
        - Si l'article concerne des produits/march√©s non mentionn√©s dans le profil ‚Üí Score faible
        - Soyez tr√®s strict sur la correspondance avec le profil utilisateur

        R√©pondez EXACTEMENT dans ce format:
        Pertinence: [Tr√®s pertinent/Mod√©r√©ment pertinent/Peu pertinent/Non pertinent]
        Score: [nombre entre 0 et 100]
        R√©sum√©: [En 1-2 phrases, expliquez la correspondance ou non-correspondance avec le profil utilisateur]
        """
        
        try:
            response = self.client.chat.completions.create(
                messages=[{"role": "user", "content": prompt}],
                model=self.GROQ_MODEL,
                temperature=0.0,  # Plus d√©terministe pour l'√©valuation
                max_tokens=self.MAX_TOKENS_EVALUATE,
            )
            
            content = response.choices[0].message.content
            return self._parse_evaluation(content)
            
        except Exception as e:
            st.error(f"Erreur API Groq: {e}. Veuillez v√©rifier votre cl√© API Groq et votre connexion r√©seau.")
            return "Non pertinent", "Erreur d'√©valuation", 0
    
    def _parse_evaluation(self, response: str) -> Tuple[str, str, int]:
        """Parse la r√©ponse de l'API pour extraire pertinence, score et r√©sum√©."""
        # Valeurs par d√©faut s√©curis√©es
        pertinence_level = "Non pertinent"
        summary = "Impossible d'√©valuer"
        score = 0
        
        if not response:
            return pertinence_level, summary, score
        
        try:
            lines = response.split('\n')
            for line in lines:
                line_stripped = line.strip() # For whitespace
                if line_stripped.lower().startswith("pertinence:"):
                    level_text = line_stripped[len("Pertinence:"):].strip()
                    # Validation des niveaux accept√©s
                    valid_levels = ["Tr√®s pertinent", "Mod√©r√©ment pertinent", "Peu pertinent", "Non pertinent"]
                    if level_text in valid_levels: # Preserves original casing if valid
                        pertinence_level = level_text
                    # Handle cases where LLM might output "Pertinence: Tr√®s Pertinent" (title case)
                    # by checking title case version if direct match fails.
                    elif level_text.title() in valid_levels:
                         pertinence_level = level_text.title()

                elif line_stripped.lower().startswith("score:"):
                    score_text = line_stripped[len("Score:"):].strip()
                    try:
                        # Extraction du nombre m√™me s'il y a du texte autour
                        score_match = re.search(r'\d+', score_text)
                        if score_match:
                            score = int(score_match.group())
                            score = max(0, min(100, score))  # Clamp entre 0 et 100
                    except (ValueError, AttributeError):
                        score = 0 # Default if parsing fails
                elif line_stripped.lower().startswith("r√©sum√©:"): # French 'R√©sum√©'
                    summary_text = line_stripped[len("R√©sum√©:"):].strip()
                    if summary_text: # Ensure not empty
                        summary = summary_text[:300]  # Limite la taille
        
        except Exception as e:
            st.warning(f"Erreur lors du parsing de l'√©valuation : {e}")
        
        return pertinence_level, summary, score

@st.cache_data(ttl=1800, show_spinner="R√©cup√©ration RSS...")
def fetch_rss_feed(url: str) -> List[Dict]:
    """R√©cup√®re les entr√©es RSS avec gestion d'erreur am√©lior√©e."""
    try:
        # Headers pour √©viter les blocages
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        # Tentative avec requests d'abord pour les URLs probl√©matiques
        if 'health.belgium.be' in url:
            try:
                response = requests.get(url, headers=headers, timeout=10)
                response.raise_for_status()
                feed = feedparser.parse(response.content)
            except Exception as e:
                st.warning(f"Erreur requests pour {url}, tentative feedparser direct: {e}")
                feed = feedparser.parse(url)
        else:
            feed = feedparser.parse(url)
        
        if feed.bozo and feed.bozo_exception:
            st.warning(f"Probl√®me de parsing pour {url}: {feed.bozo_exception}")
        
        return feed.entries
        
    except Exception as e:
        st.error(f"Erreur RSS {url}: {e}")
        return []

def fetch_all_articles(feeds: Dict[str, str], start_date: datetime.date, end_date: datetime.date, clean_html: bool = True) -> List[Dict]:
    """R√©cup√®re tous les articles en parall√®le avec extraction optimis√©e du contenu."""
    all_articles = []
    failed_feeds = []
    
    # R√©cup√©ration de l'option de formatage depuis session_state ou valeur par d√©faut
    preserve_formatting = st.session_state.get('preserve_formatting', True)
    
    with st.spinner("R√©cup√©ration des flux RSS..."):
        progress_bar = st.progress(0)
        
        for idx, (source_name, url) in enumerate(feeds.items()):
            try:
                with st.spinner(f"R√©cup√©ration de {source_name}..."):
                    entries = fetch_rss_feed(url)
                    
                    if not entries:
                        st.warning(f"Aucune entr√©e trouv√©e pour {source_name}")
                        if source_name not in failed_feeds: # Avoid duplicates
                            failed_feeds.append(source_name)
                        continue
                
                for entry in entries:
                    try:
                        published_date = None
                        
                        # Gestion am√©lior√©e des dates
                        if hasattr(entry, 'published_parsed') and entry.published_parsed:
                            published_date = datetime(*entry.published_parsed[:6]).date()
                        elif hasattr(entry, 'updated_parsed') and entry.updated_parsed:
                            published_date = datetime(*entry.updated_parsed[:6]).date()
                        elif hasattr(entry, 'published'):
                            try:
                                # Essayer diff√©rents formats de date
                                for fmt in ['%a, %d %b %Y %H:%M:%S %Z', '%a, %d %b %Y %H:%M:%S %z', '%Y-%m-%d']:
                                    try:
                                        published_date = datetime.strptime(entry.published, fmt).date()
                                        break
                                    except ValueError:
                                        continue
                            except Exception as e_parse_str_date:
                                # If parsing fails, default to now, and optionally log or inform user
                                # For now, just using a default. A debug message could be added.
                                # st.sidebar.caption(f"Debug: Date parse error for '{entry.get('title', 'Unknown title')}', used current date. Error: {e_parse_str_date}")
                                published_date = datetime.now().date()
                        
                        # Si pas de date trouv√©e, utiliser la date actuelle
                        if not published_date:
                            published_date = datetime.now().date()
                        
                        if start_date <= published_date <= end_date:
                            # Extraction optimis√©e du contenu
                            raw_content = extract_content_from_entry(entry)
                            
                            # Validation du contenu
                            if not raw_content or len(raw_content.strip()) < 10:
                                raw_content = getattr(entry, 'title', 'Contenu non disponible')
                            
                            # Nettoyage HTML optionnel
                            if clean_html:
                                summary = clean_html_content(raw_content, preserve_basic_formatting=preserve_formatting)
                            else:
                                summary = raw_content
                            
                            # Validation finale
                            if not summary or len(summary.strip()) < 5:
                                summary = "R√©sum√© non disponible"
                            
                            all_articles.append({
                                "source": source_name,
                                "title": getattr(entry, 'title', 'Titre non disponible'),
                                "summary": summary,
                                "raw_content": raw_content,
                                "link": getattr(entry, 'link', '#'),
                                "published": published_date
                            })
                            
                    except Exception as e:
                        st.warning(f"Erreur lors du traitement d'un article de {source_name}: {e}")
                        continue
                        
                progress_bar.progress((idx + 1) / len(feeds))
                
            except Exception as e:
                st.error(f"Erreur lors de la r√©cup√©ration de {source_name}: {e}")
                if source_name not in failed_feeds: # Avoid duplicates
                    failed_feeds.append(source_name)
                continue
    
    st.success(f"‚úÖ {len(all_articles)} articles r√©cup√©r√©s au total")

    if failed_feeds:
        unique_failed_feeds = sorted(list(set(failed_feeds)))
        st.warning(f"‚ö†Ô∏è Probl√®mes rencontr√©s avec les flux suivants : {', '.join(unique_failed_feeds)}. Certains articles de ces sources pourraient manquer.")

    return all_articles

# --- Interface Streamlit optimis√©e ---

st.set_page_config(
    page_title="Veille R√©glementaire Food Safety", 
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("üîç Veille R√©glementaire - S√©curit√© Alimentaire")
st.markdown("*Application optimis√©e pour consultants et auditeurs food safety*")
st.markdown("‚ú® **Nouveau** : Extraction optimis√©e du contenu RSS (content:encoded pour Health BE)")

# Sidebar pour la configuration
with st.sidebar:
    st.header("‚öôÔ∏è Configuration")
    
    # Seuil de pertinence
    min_pertinence_score = st.slider(
        "Score minimum de pertinence", 
        min_value=0, 
        max_value=100, 
        value=60,
        help="Articles avec un score inf√©rieur seront filtr√©s"
    )
    
    # Nombre max d'articles
    max_articles = st.selectbox(
        "Nombre maximum d'articles √† √©valuer",
        [10, 20, 50, 100],
        index=1
    )
    
    # Options de parsing
    st.subheader("üîß Options de parsing")
    
    st.session_state['clean_html'] = st.checkbox(
        "Nettoyer le HTML des r√©sum√©s",
        value=True,
        help="Convertit le HTML en texte lisible (recommand√© pour Health BE)"
    )
    
    st.session_state['preserve_formatting'] = st.checkbox(
        "Pr√©server le formatage de base",
        value=True,
        help="Garde les paragraphes et listes lors du nettoyage HTML"
    )
    
    # Option de traduction
    st.session_state['translate_to_french'] = st.checkbox(
        "üá´üá∑ Traduire le contenu en fran√ßais",
        value=False,
        help="Traduit automatiquement les titres et r√©sum√©s en fran√ßais (utilise l'API Groq)"
    )
    
    # Information sur l'extraction de contenu
    with st.expander("‚ÑπÔ∏è Extraction de contenu"):
        st.markdown("""
        **Ordre de priorit√© pour le contenu:**
        1. `content:encoded` (plus d√©taill√©, notamment Health BE)
        2. `summary/description` (fallback standard)
        3. `title` (fallback minimal)
        
        **Health BE** : Utilise `content:encoded` avec HTML riche
        
        **üá´üá∑ Traduction** : Les articles EFSA/EU (en anglais) peuvent √™tre traduits automatiquement
        """)
    
# --- Profil utilisateur (simplifi√©) ---
with st.expander("üè¢ Profil d'Activit√©", expanded=True):
    col1, col2 = st.columns(2)
    
    with col1:
        selected_product_types = st.multiselect(
            "Types de Produits",
            PRODUCT_TYPES,
            default=["Autre"]
        )
        
        selected_risk_types = st.multiselect(
            "Types de Risques",
            RISK_TYPES,
            default=["Microbiologique", "Chimique"]
        )
    
    with col2:
        selected_markets = st.multiselect(
            "March√©s Cibles",
            MARKETS,
            default=["UE", "France"]
        )
        
        main_concerns = st.text_area(
            "Pr√©occupations Sp√©cifiques",
            placeholder="Ex: PFAS, Listeria, nouvelles r√©glementations EU...",
            height=100
        )

# Cr√©ation du contexte utilisateur
user_context = f"""
Types de Produits: {', '.join(selected_product_types)}
Types de Risques: {', '.join(selected_risk_types)}
March√©s: {', '.join(selected_markets)}
Pr√©occupations: {main_concerns}
Profil: Consultant/Auditeur en s√©curit√© alimentaire europ√©enne
"""

# --- Configuration p√©riode et API ---
col1, col2, col3 = st.columns([2, 2, 3])

with col1:
    start_date = st.date_input("üìÖ Date de D√©but", datetime.now() - timedelta(days=7))

with col2:
    end_date = st.date_input("üìÖ Date de Fin", datetime.now())

with col3:
    groq_api_key = os.getenv("GROQ_API_KEY") or st.secrets.get("GROQ_API_KEY")
    if not groq_api_key:
        groq_api_key = st.text_input("üîë Cl√© API Groq", type="password", 
                                   help="N√©cessaire pour l'√©valuation de pertinence")

# --- Lancement de la veille ---
if st.button("üöÄ Lancer la Veille", type="primary", use_container_width=True, disabled=not groq_api_key):
    if not groq_api_key:
        st.error("Cl√© API Groq requise pour l'√©valuation de pertinence")
        st.stop()
    
    if start_date > end_date:
        st.error("La date de fin doit √™tre post√©rieure √† la date de d√©but")
        st.stop()
    
    # R√©cup√©ration des articles
    all_articles = fetch_all_articles(FRENCH_EU_RSS_FEEDS, start_date, end_date, st.session_state.get('clean_html', True))
    
    if not all_articles:
        st.warning("Aucun article trouv√© dans la p√©riode sp√©cifi√©e")
        st.stop()
    
    # Limitation du nombre d'articles √† √©valuer
    all_articles = all_articles[:max_articles]
    
    # Message informatif sur la traduction
    translate_to_french = st.session_state.get('translate_to_french', False)
    if translate_to_french:
        st.info(f"üá´üá∑ **Mode traduction activ√©** : Les titres et r√©sum√©s en anglais seront traduits automatiquement")
        st.info("‚û°Ô∏è V√©rifiez la sidebar pour les d√©tails de traduction en temps r√©el")
    
    st.info(f"üîç √âvaluation de {len(all_articles)} articles...")
    
    # √âvaluation des articles avec traduction optionnelle
    evaluator = ArticleEvaluator(groq_api_key)
    evaluated_articles = []
    
    progress_bar = st.progress(0)
    progress_text = st.empty()
    
    # Option de traduction et conteneur de debug
    translate_to_french = st.session_state.get('translate_to_french', False)
    translation_debug = None
    
    if translate_to_french:
        # Cr√©er un conteneur de debug dans la sidebar
        with st.sidebar:
            st.markdown("**üîç Debug Traduction en cours:**")
            translation_debug = st.empty()
    
    for idx, article in enumerate(all_articles):
        progress_text.text(f"√âvaluation {idx+1}/{len(all_articles)}: {article['source']}")
        
        # Traduction optionnelle AVANT √©valuation
        current_title = article['title']
        current_summary = article['summary']
        translation_performed_for_article = False # Pour marquer si au moins un des champs a √©t√© r√©ellement chang√©
        
        if translate_to_french:
            progress_text.text(f"Traduction {idx+1}/{len(all_articles)}: {article['source']}")
            
            original_title = article['title']
            original_summary = article['summary']

            translated_title_text, title_translation_attempted = evaluator.translate_to_french(original_title, "titre")
            summary_translation_text, summary_translation_attempted = evaluator.translate_to_french(original_summary, "r√©sum√©")

            title_changed = (translated_title_text != original_title)
            summary_changed = (summary_translation_text != original_summary)

            current_title = translated_title_text
            current_summary = summary_translation_text
            
            if title_changed or summary_changed:
                translation_performed_for_article = True

            # Debug info dans la sidebar
            if translation_debug is not None:
                # Titre
                if not title_translation_attempted:
                    translation_debug.info(f"‚ÑπÔ∏è Titre Art.{idx+1} ({article['source']}): Non traduit (d√©j√† FR)")
                elif title_changed:
                    translation_debug.success(f"‚úÖ Titre Art.{idx+1} ({article['source']}): Traduit")
                else: # Tentative mais pas de changement ou √©chec qualit√©
                    translation_debug.warning(f"‚ö†Ô∏è Titre Art.{idx+1} ({article['source']}): Original conserv√© (trad. insatisfaisante/√©chec)")

                # R√©sum√©
                if not summary_translation_attempted:
                    translation_debug.info(f"‚ÑπÔ∏è R√©sum√© Art.{idx+1} ({article['source']}): Non traduit (d√©j√† FR)")
                elif summary_changed:
                    translation_debug.success(f"‚úÖ R√©sum√© Art.{idx+1} ({article['source']}): Traduit")
                else: # Tentative mais pas de changement ou √©chec qualit√©
                    translation_debug.warning(f"‚ö†Ô∏è R√©sum√© Art.{idx+1} ({article['source']}): Original conserv√© (trad. insatisfaisante/√©chec)")

        progress_text.text(f"√âvaluation {idx+1}/{len(all_articles)}: {article['source']}")
        
        # √âvaluation avec le contenu (possiblement traduit)
        pertinence_level, evaluation_summary, score = evaluator.evaluate_pertinence(
            current_title,
            current_summary,
            user_context
        )
        
        # Filtrage bas√© sur le score minimum
        if score >= min_pertinence_score:
            evaluated_articles.append({
                "Source": article['source'],
                "Titre": current_title,  # Titre possiblement traduit
                "R√©sum√©": current_summary,  # R√©sum√© possiblement traduit
                "Titre Original": article['title'],  # Garde l'original pour r√©f√©rence
                "R√©sum√© Original": article['summary'],  # Garde l'original pour r√©f√©rence
                "Lien": article['link'],
                "Date de Publication": article['published'].strftime('%Y-%m-%d'),
                "Niveau de Pertinence": pertinence_level,
                "Score": score,
                "√âvaluation de la Pertinence": evaluation_summary,
                "raw_content": article.get('raw_content', ''),
                "Traduit": translation_performed_for_article # Utilise le nouveau flag
            })
        
        progress_bar.progress((idx + 1) / len(all_articles))
    
    progress_text.empty()
    progress_bar.empty()
    
    # Nettoyage du debug de traduction
    if translate_to_french and translation_debug is not None:
        translation_debug.empty()
    
    # Affichage des r√©sultats
    if evaluated_articles:
        # Tri par score d√©croissant
        evaluated_articles.sort(key=lambda x: x['Score'], reverse=True)
        
        st.success(f"‚úÖ {len(evaluated_articles)} articles pertinents trouv√©s (score ‚â• {min_pertinence_score})")
        
        # M√©triques
        col1, col2, col3, col4 = st.columns(4)
        
        score_stats = [a['Score'] for a in evaluated_articles]
        with col1:
            st.metric("Score Moyen", f"{sum(score_stats)/len(score_stats):.1f}/100")
        with col2:
            very_pertinent = len([a for a in evaluated_articles if a['Score'] >= 80])
            st.metric("Tr√®s Pertinents", very_pertinent)
        with col3:
            moderate_pertinent = len([a for a in evaluated_articles if 60 <= a['Score'] < 80])
            st.metric("Mod√©r√©ment Pertinents", moderate_pertinent)
        with col4:
            st.metric("Score Max", f"{max(score_stats)}/100")
        
        # AFFICHAGE SIMPLE - AUCUN data_editor !
        st.subheader("üìä Articles S√©lectionn√©s")
        
        # 1. Vue d'ensemble avec tableau simple
        st.markdown("### üìã Vue d'ensemble")
        
        # Pr√©paration simple des donn√©es
        simple_data = []
        for article in evaluated_articles:
            score_visual = f"‚≠ê {article['Score']}/100 " + ("üü¢" if article['Score'] >= 80 else "üü°" if article['Score'] >= 60 else "üü†")
            lien_status = "üîó Disponible" if article['Lien'] != '#' else "‚ùå Indisponible"
            
            # Indicateur de traduction
            title_display = article['Titre'][:80] + ("..." if len(article['Titre']) > 80 else "")
            if article.get('Traduit', False):
                title_display = f"üá´üá∑ {title_display}"
            
            simple_data.append({
                'Source': article['Source'],
                'Titre': title_display,
                'Score': score_visual,
                'Date': article['Date de Publication'],
                'Lien': lien_status
            })
        
        # Affichage tableau simple
        simple_df = pd.DataFrame(simple_data)
        st.dataframe(simple_df, use_container_width=True)
        
        # 2. S√©lection pour export
        st.markdown("### üì• S√©lection pour Export")
        
        options_for_export = []
        for idx, article in enumerate(evaluated_articles):
            # Ajoute un indicateur de traduction dans le label
            translation_indicator = " üá´üá∑" if article.get('Traduit', False) else ""
            label = f"‚≠ê{article['Score']} - {article['Source']} - {article['Titre'][:50]}...{translation_indicator}"
            options_for_export.append((idx, label))
        
        selected_indices = st.multiselect(
            "S√©lectionnez les articles √† exporter :",
            options=[opt[0] for opt in options_for_export],
            format_func=lambda x: next(opt[1] for opt in options_for_export if opt[0] == x),
            default=list(range(min(5, len(options_for_export))))
        )
        
        # 3. Affichage d√©taill√©
        if selected_indices:
            st.markdown(f"### üìñ D√©tails des {len(selected_indices)} articles s√©lectionn√©s")
            
            for idx in selected_indices:
                if idx < len(evaluated_articles):
                    article = evaluated_articles[idx]
                    
                    with st.expander(f"‚≠ê {article['Score']}/100 - {article['Source']} - {article['Titre'][:60]}..."):
                        col1, col2 = st.columns([3, 1])
                        
                        with col1:
                            # Affichage du titre avec indicateur de traduction
                            if article.get('Traduit', False):
                                st.markdown(f"**üì∞ Titre (üá´üá∑ traduit) :** {article['Titre']}")
                                with st.expander("üëÅÔ∏è Voir le titre original"):
                                    st.markdown(f"**üî§ Original :** {article.get('Titre Original', 'N/A')}")
                            else:
                                st.markdown(f"**üì∞ Titre :** {article['Titre']}")
                            
                            # Affichage du r√©sum√© avec indicateur de traduction
                            if article.get('Traduit', False):
                                st.markdown(f"**üìù R√©sum√© (üá´üá∑ traduit) :**")
                                st.write(article['R√©sum√©'])
                                with st.expander("üëÅÔ∏è Voir le r√©sum√© original"):
                                    st.write(article.get('R√©sum√© Original', 'N/A'))
                            else:
                                st.markdown(f"**üìù R√©sum√© :**")
                                st.write(article['R√©sum√©'])
                            
                            st.markdown(f"**üîç √âvaluation :**")
                            st.write(article['√âvaluation de la Pertinence'])
                        
                        with col2:
                            st.markdown(f"**üì° Source :** {article['Source']}")
                            st.markdown(f"**‚≠ê Score :** {article['Score']}/100")
                            st.markdown(f"**üìÖ Date :** {article['Date de Publication']}")
                            
                            if article['Lien'] != '#':
                                st.markdown(f"**[üîó Ouvrir l'article]({article['Lien']})**")
                            else:
                                st.markdown("**‚ùå Lien indisponible**")
        else:
            st.info("S√©lectionnez des articles ci-dessus pour voir les d√©tails")
        
        # 4. Debug
        if st.sidebar.checkbox("üî¨ Mode Debug - Afficher contenu brut"):
            st.markdown("### üî¨ Comparaison Contenu Nettoy√© vs Brut")
            
            debug_article_idx = st.selectbox(
                "S√©lectionnez un article pour le debug :",
                range(len(evaluated_articles)),
                format_func=lambda x: f"{evaluated_articles[x]['Source']} - {evaluated_articles[x]['Titre'][:50]}..."
            )
            
            if debug_article_idx < len(evaluated_articles):
                article = evaluated_articles[debug_article_idx]
                
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("**üìù Contenu Nettoy√©:**")
                    st.text_area("", article['R√©sum√©'], height=200, key="clean_content_debug")
                
                with col2:
                    st.markdown("**üîß Contenu Brut (HTML):**")
                    raw_content = article.get('raw_content', 'Non disponible')
                    st.text_area("", raw_content, height=200, key="raw_content_debug")
        
        # T√©l√©chargement
        if len(evaluated_articles) > 0:
            st.subheader("üíæ T√©l√©chargement")
            
            col1, col2, col3 = st.columns(3)
            
            # Pr√©paration donn√©es export (nettoie les colonnes techniques)
            if selected_indices:
                selected_articles_data = [evaluated_articles[i] for i in selected_indices if i < len(evaluated_articles)]
                # Nettoyage pour export
                clean_articles = []
                for article in selected_articles_data:
                    clean_article = {
                        'Source': article['Source'],
                        'Titre': article['Titre'],
                        'R√©sum√©': article['R√©sum√©'],
                        'Lien': article['Lien'],
                        'Date de Publication': article['Date de Publication'],
                        'Niveau de Pertinence': article['Niveau de Pertinence'],
                        'Score': article['Score'],
                        '√âvaluation de la Pertinence': article['√âvaluation de la Pertinence']
                    }
                    # Ajoute les versions originales si traduit
                    if article.get('Traduit', False):
                        clean_article['Titre Original'] = article.get('Titre Original', '')
                        clean_article['R√©sum√© Original'] = article.get('R√©sum√© Original', '')
                        clean_article['Traduit'] = 'Oui'
                    else:
                        clean_article['Traduit'] = 'Non'
                    clean_articles.append(clean_article)
                
                export_df = pd.DataFrame(clean_articles)
                st.success(f"üìå {len(selected_articles_data)} articles s√©lectionn√©s pour l'export")
            else:
                # M√™me nettoyage pour tous les articles
                clean_articles = []
                for article in evaluated_articles:
                    clean_article = {
                        'Source': article['Source'],
                        'Titre': article['Titre'],
                        'R√©sum√©': article['R√©sum√©'],
                        'Lien': article['Lien'],
                        'Date de Publication': article['Date de Publication'],
                        'Niveau de Pertinence': article['Niveau de Pertinence'],
                        'Score': article['Score'],
                        '√âvaluation de la Pertinence': article['√âvaluation de la Pertinence']
                    }
                    if article.get('Traduit', False):
                        clean_article['Titre Original'] = article.get('Titre Original', '')
                        clean_article['R√©sum√© Original'] = article.get('R√©sum√© Original', '')
                        clean_article['Traduit'] = 'Oui'
                    else:
                        clean_article['Traduit'] = 'Non'
                    clean_articles.append(clean_article)
                
                export_df = pd.DataFrame(clean_articles)
                st.info("üìå Aucune s√©lection - tous les articles seront export√©s")
            
            with col1:
                csv_data = export_df.to_csv(index=False).encode('utf-8')
                st.download_button(
                    label="üì• T√©l√©charger CSV",
                    data=csv_data,
                    file_name=f"veille_food_safety_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
                    mime="text/csv",
                    use_container_width=True
                )
            
            with col2:
                excel_buffer = BytesIO()
                with pd.ExcelWriter(excel_buffer, engine='xlsxwriter') as writer:
                    export_df.to_excel(writer, sheet_name='Veille Food Safety', index=False)
                
                excel_buffer.seek(0)
                st.download_button(
                    label="üì• T√©l√©charger Excel",
                    data=excel_buffer,
                    file_name=f"veille_food_safety_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True
                )
            
            with col3:
                if selected_indices:
                    scores = [evaluated_articles[i]['Score'] for i in selected_indices if i < len(evaluated_articles)]
                    if scores:
                        avg_score = sum(scores) / len(scores)
                        st.metric("Score Moyen S√©lection", f"{avg_score:.1f}/100")
                else:
                    st.info("Aucune s√©lection active")
    
    else:
        st.warning(f"‚ùå Aucun article avec un score ‚â• {min_pertinence_score} trouv√©. Essayez de r√©duire le seuil de pertinence.")

# Footer
st.markdown("---")
st.markdown("*D√©velopp√© pour les professionnels de la s√©curit√© alimentaire europ√©enne*")
